---
title: "Predicting the exercise quality from the Weight lifting exercise measures"
author: "Lena Stevanoska"
date: "25 December 2015"
output: html_document
---

##Summary

This is a report from building a prediction model for the quality of the Weight lifting exercises based on the measures gathered during the weight lifting exercise performed by 6 people. 
They were asked to do the same exercises in 1 correct way and 5 wrong ways. Each of these different ways of exercising were marked as different classes. 
The training data was used to create a prediction model that was later on used to predict the 20 test cases.
Initial investigation was done to establish the best prediction model using different techniques. The chosen prediction model had **0.9931** Accuracy on the validation dataset.
The data used here comes from the original study that can be found [here](http://groupware.les.inf.puc-rio.br/har)


## Data analysis and preprocessing


The data from the plm-training.csv file was first analysed and cleaned before dividing it into training and validation datasets, using the variable **"classe"** and ensuring the training dataset has **75%** of the observations.

```{r loaddata, echo=FALSE, results='hide', message=FALSE, warning=FALSE, cache=TRUE}
library(plyr)
library(dplyr)
library(caret)
library(ggplot2)
rm(list=ls())
dat<-read.csv('data\\pml-training.csv')
set.seed(12346)
nsv <- nearZeroVar(dat,saveMetrics=TRUE)
nsv_positions <- nearZeroVar(dat,saveMetrics=FALSE)
filtered_training <- dat[-c(nsv_positions)]
excluding_vars <- names(filtered_training) %in% c("X","user_name","raw_timestamp_part_1","raw_timestamp_part_2","cvtd_timestamp","new_window","num_window")
filtered_training  <- filtered_training[!excluding_vars]
exclude_cols <- grep("^var|^avg|^max|^min|^std|^amplitude",names(filtered_training))
filtered_training <- filtered_training[-c(exclude_cols)]
filtered_training_no_class <- filtered_training[-c(dim(filtered_training))]
correlated_cols_to_exclude <- findCorrelation(cor(filtered_training_no_class), cutoff= 0.75)
corvars<-names(filtered_training)[correlated_cols_to_exclude]
filtered_training <- filtered_training[-c(correlated_cols_to_exclude)]
filtered_partition = createDataPartition(filtered_training$classe, p=0.75, list=F)

training <- filtered_training[filtered_partition,]
probe <- filtered_training[-filtered_partition,]

trainobs<-dim(training)[1]
testobs<-dim(probe)[1]
inivar<-dim(probe)[2]
nzv<-length(nsv)

rm(dat,filtered_training)

```

First step in the cleaning of the data was identifying the values with near zero variability. There were **`r nzv`** variables identified using the function from the caret package that diagnoses predictors that have one unique value (i.e. are zero variance predictors) or predictors that have both of the following characteristics: they have very few unique values relative to the number of samples and the ratio of the frequency of the most common value to the frequency of the second most common value is large (definition of the function found [here](http://www.inside-r.org/packages/cran/caret/docs/nearZeroVar)). After manual review of the variables, they were removed from the training dataset, since they might break our model by providing a constant value across all observations.

Since this model needs to predict the quality of the exercise based on the measurements from the actions performed regardless of who is performing it and when, I've removed the variables that were related to the user name, timestamp, order, window number and the indication if it's a new window. Also, all the variables that have been added by the initial research team, like average, variability, min, max, std or amplitude were removed, since they were created after processing of the initial input values. As a final step in the cleaning process, all variables that have correlation of more then **0.75** were excluded. They are listed below.

```{r corvar,echo=FALSE, cache=TRUE}
corvars
```

After the cleaning, the dataset was divided in 2 datasets. The training set contained  **`r trainobs`** observations and the validation set contained **`r testobs`** observations, each with **`r inivar`** variables.

The following plot show the distribution of the quality of the exercises from the training dataset.

```{r plotanal,echo=FALSE,warning=FALSE,message=FALSE}
library(ggplot2)

g<-qplot(training$classe, colour=training$classe,fill=training$classe,xlab = "Exercise quality type")
g<-g+theme_bw()+theme(legend.position="none")
g
```



## Model selection

First a classification tree was fitted using the train function from the caret package. But, as the confusion matrix shows below, the accuracy on the validation dataset was under **54%**. Hence, this model was disregarded.

```{r modelclasstree, echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE}
modFit<-train(classe~.,method="rpart",data=training)
pred2<-predict(modFit,newdata=probe)

confusionMatrix(pred2,probe$classe)

```

Next model that was tested was the random forest model, built using the train function from the caret package on the training dataset with the proximity parameter set to TRUE.

```{r modelrandomfores, echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE}
classeFit <- train(training$classe ~., data=training, method="rf",prox=TRUE)

```

Below is the output of the confusion matrix of the prediction on the validation dataset using the final model from the random forest model building. 

```{r modelrandomforescheck, echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE}
pred <- predict(classeFit,probe)
confusionMatrix(pred,probe$classe)

```

As shown, the model has excellent accuracy of **99.31%** on the validation dataset, and as displayed below the final model has **0.76%** OOB (out-of-bag) estimate of error rate on the training dataset. 

These results, together with the fact that the {caret} **train** function with the (**rf**) random forest algorithm uses cross-validation internally as per the documentation available [here](http://topepo.github.io/caret/training.html) and thus, we do not need to use other methods for partitioning our dataset beyond what we used above.

```{r modelrfvarimp, echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE}
classeFit$finalModel

```



#Results on the test set

In order to get the results for the 20 test cases, the same cleaning process that was conducted on the training dataset was performed on the test dataset.

The predicted values for the classe variable for the 20 cases are displayed below.

```{r resultset, echo=FALSE, message=FALSE, warning=FALSE, cache=TRUE}

dattest<-read.csv('data\\pml-testing.csv')

test_set <- dattest[-c(nsv_positions)]
test_set <- test_set[!excluding_vars]
test_set <- test_set[-c(exclude_cols)]
test_set <- test_set[-c(correlated_cols_to_exclude)]

predOnTest <- predict(classeFit,test_set)
predOnTest
```
